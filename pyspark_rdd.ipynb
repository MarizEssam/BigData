{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcaac1b2-f2fc-4b40-97be-f0594d8dbf49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 08:53:33 WARN Utils: Your hostname, msobhvm resolves to a loopback address: 127.0.1.1; using 192.168.238.129 instead (on interface ens33)\n",
      "23/05/02 08:53:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 08:53:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"first app\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PySpark Create RDD example\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61719ed2-ffef-472f-a5ba-37216dd7d605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = sc.parallelize (\n",
    "   [\"scala\", \n",
    "   \"java\", \n",
    "   \"hadoop\", \n",
    "   \"spark\", \n",
    "   \"akka\",\n",
    "   \"spark vs hadoop\", \n",
    "   \"pyspark\",\n",
    "   \"pyspark and spark\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3538e0-b4cc-4fd2-a480-c766b6f3b4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#action: count items\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36aa7cb5-6a9e-4e1e-894e-5caa89dc4bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scala',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'akka',\n",
       " 'spark vs hadoop',\n",
       " 'pyspark',\n",
       " 'pyspark and spark']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#action: Generate local collection\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "affe708f-b401-4147-80d1-16ffcb0a3b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scala\n",
      "java\n",
      "hadoop\n",
      "spark\n",
      "akka\n",
      "spark vs hadoop\n",
      "pyspark\n",
      "pyspark and spark\n"
     ]
    }
   ],
   "source": [
    "#action: for each item call custom function\n",
    "def f(x): print(x)\n",
    "\n",
    "words.foreach(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b12a26f-9f4a-4bc5-9e83-3a74ab438561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark', 'spark vs hadoop', 'pyspark', 'pyspark and spark']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: apply filter\n",
    "result_rdd = words.filter(lambda x: 'spark' in x)\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d73435-8e31-4c51-82cf-13617ccd778d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scala', 1),\n",
       " ('java', 1),\n",
       " ('hadoop', 1),\n",
       " ('spark', 1),\n",
       " ('akka', 1),\n",
       " ('spark vs hadoop', 1),\n",
       " ('pyspark', 1),\n",
       " ('pyspark and spark', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: map items to another item with different form. EX: ('The') -> ('The', 1)\n",
    "result_rdd = words.map(lambda x: (x, 1))\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaeccc62-be71-46ac-ba14-e60de7a0b896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|               _1| _2|\n",
      "+-----------------+---+\n",
      "|            scala|  1|\n",
      "|             java|  1|\n",
      "|           hadoop|  1|\n",
      "|            spark|  1|\n",
      "|             akka|  1|\n",
      "|  spark vs hadoop|  1|\n",
      "|          pyspark|  1|\n",
      "|pyspark and spark|  1|\n",
      "+-----------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#action: extract data frame from RDD\n",
    "result_rdd = words.map(lambda x: (x, 1))\n",
    "df = result_rdd.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe0d18a-11d4-4b10-a36b-1e6ac21e5461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: map item -> another items. EX: (4) -> (1), (2), (3)\n",
    "rdd = sc.parallelize([2, 3, 4])\n",
    "result_rdd = rdd.flatMap(lambda x: range(1, x))\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebc4151-5b3f-4544-88c1-44a668477ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 3: 4}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#action: generate local collection using dictionry map form\n",
    "result_rdd = sc.parallelize([(1, 2), (3, 4)])\n",
    "result_rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31670a07-9cae-4766-ba13-c008db77b6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding all the elements -> 15\n"
     ]
    }
   ],
   "source": [
    "#action: reduce\n",
    "from operator import add\n",
    "nums = sc.parallelize([1, 2, 3, 4, 5])\n",
    "sum = nums.reduce(add)\n",
    "print(\"Adding all the elements -> %i\" % (sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46948f1b-0d18-4d6b-a34c-4f1ba8a964ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 1),\n",
       " ('apple', 2),\n",
       " ('apple', 5),\n",
       " ('orange', 3),\n",
       " ('orange', 5),\n",
       " ('orange', 9),\n",
       " ('banana', 2),\n",
       " ('banana', 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: map item -> another item/items pairs. EX: ('apple', [1, 2, 5]) -> ('apple', 1), ('apple', 2), ('apple', 5)\n",
    "rdd = sc.parallelize([('apple', [1, 2, 5]), ('orange', [3, 5, 9]), ('banana', [2, 4])])\n",
    "result_rdd = rdd.flatMapValues(lambda x: x)\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ebaafd6-d0a5-4d01-a67d-6c42a4fed29a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hadoop', (4, 5)), ('spark', (1, 2))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: join\n",
    "x = sc.parallelize([(\"spark\", 1), (\"hadoop\", 4)])\n",
    "y = sc.parallelize([(\"spark\", 2), (\"hadoop\", 5)])\n",
    "result_rdd = x.join(y)\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e98eae0b-efcf-4d7b-bab3-fda4ec517463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('banana', 12), ('apple', 15), ('orange', 22)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: sort/sort by key\n",
    "data = [('apple', 15), ('orange', 22), ('banana', 12)]\n",
    "result_rdd = sc.parallelize(data).sortBy(lambda x: x[1])\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32821d7-7a59-4aee-be47-77c414284cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('orange', 22), ('banana', 12), ('apple', 15)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rdd = sc.parallelize(data).sortBy(lambda x: x[0], False)\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d868ec36-ea28-41b9-985d-6a5af40da091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transform: keys/values\n",
    "data = [('ahmed', 'math'), ('ahmed', 'physics'), ('mostafa', 'math'), ('said', 'math'), ('salme', 'history'), ('fady', 'math')]\n",
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb9e5e9-6902-4536-941b-45f456bf6de3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahmed', 'ahmed', 'mostafa', 'said', 'salme', 'fady']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a80402c0-e5b8-4330-bf76-eadd6a5db0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['math', 'physics', 'math', 'math', 'history', 'math']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.values().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b1f3d5-2c0f-4cb1-a483-d410d4896f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('b', 4), ('b', 5)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: operations\n",
    "rdd1 = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 3)])\n",
    "rdd2 = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
    "result_rdd = rdd1.subtract(rdd2)\n",
    "result_rdd.collect()\n",
    "result_rdd = rdd1.subtractByKey(rdd2)\n",
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9be6fbe-6342-4137-ace0-d317248a5593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| _1|                  _2|\n",
      "+---+--------------------+\n",
      "|  1|{[1, 1, 3, 5], 0, 4}|\n",
      "|  0|      {[2, 8], 0, 2}|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transform: group by\n",
    "rdd = sc.parallelize([1, 1, 2, 3, 5, 8])\n",
    "result_rdd = rdd.groupBy(lambda x: x % 2)\n",
    "result_rdd.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd6f2ea-363d-46fb-ab78-853c926f9bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'ahmed': 2, 'mostafa': 1, 'said': 1, 'salme': 1, 'fady': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#action: count by key\n",
    "data = [('ahmed', 'math'), ('ahmed', 'physics'), ('mostafa', 'math'), ('said', 'math'), ('salme', 'history'), ('fady', 'math')]\n",
    "sc.parallelize(data).countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8fe8d54-55b7-48a5-9ead-29075a7ff039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 60.0\n",
      "min: 2.0\n",
      "max: 43.0\n",
      "stdev: 16.416455159382004\n",
      "variance: 269.5\n",
      "sampleStdev: 18.95608961081724\n",
      "sampleVariance: 359.3333333333333\n",
      "sumApprox: 60.0\n"
     ]
    }
   ],
   "source": [
    "#action: statistics\n",
    "rdd = sc.parallelize([2.0, 5.0, 43.0, 10.0])\n",
    "print(\"sum:\", rdd.sum())\n",
    "print(\"min:\", rdd.min())\n",
    "print(\"max:\", rdd.max())\n",
    "print(\"stdev:\", rdd.stdev())\n",
    "print(\"variance:\", rdd.variance())\n",
    "print(\"sampleStdev:\", rdd.sampleStdev())\n",
    "print(\"sampleVariance:\", rdd.sampleVariance())\n",
    "print(\"sumApprox:\", rdd.sumApprox(1000, 0.95))\n",
    "#sum till 1000 ms or 0.95 confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26262823-b6fe-4473-9819-adc49fe3b108",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     Word|Count|\n",
      "+---------+-----+\n",
      "|      The|    4|\n",
      "|   Slaves|    3|\n",
      "|        a|    3|\n",
      "|       of|    3|\n",
      "|      are|    3|\n",
      "|       to|    3|\n",
      "| servers.|    3|\n",
      "|  Masters|    3|\n",
      "|  contain|    2|\n",
      "|     list|    2|\n",
      "|   hosts,|    2|\n",
      "|      one|    2|\n",
      "|      per|    2|\n",
      "|    line,|    2|\n",
      "|     that|    2|\n",
      "|     host|    2|\n",
      "|      and|    2|\n",
      "| NameNode|    2|\n",
      "|     file|    2|\n",
      "|Secondary|    2|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#word count example\n",
    "#load\n",
    "lines = sc.textFile(\"file:/home/msobh/pyspark/data/words.txt\")\n",
    "#transform\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))\n",
    "#transform\n",
    "map = words.map(lambda word: (word, 1))\n",
    "#action\n",
    "f = lambda accumulator, value: accumulator + value\n",
    "result = map.reduceByKey(f)\n",
    "#transform\n",
    "sorted = result.sortBy(lambda x: x[1], False)\n",
    "#action\n",
    "df = sorted.toDF([\"Word\", \"Count\"]); df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41ca3a-5ad7-4168-8f64-52ce304509b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
